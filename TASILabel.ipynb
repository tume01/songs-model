{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    "label_prop_model = LabelSpreading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('allsongs.json') as jsonfile:\n",
    "    data = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3513"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(item):\n",
    "    text=\"\"\n",
    "    for sentence in item:\n",
    "        sentence = sentence.replace(\"\\t\",\" \")\n",
    "        #print(sentence)\n",
    "        sentence = sentence.replace(\"\\n\",\" \")\n",
    "        sentence = sentence.replace(\"\\r\",\" \")\n",
    "        sentence = sentence.replace(\"  \",\" \")\n",
    "        sentence = sentence.replace(\"  \",\" \")\n",
    "        sentence = sentence.replace(\"  \",\" \")\n",
    "        sentence = sentence.replace(\"  \",\" \")\n",
    "        #print(sentence)\n",
    "        text = text+sentence\n",
    "        \n",
    "        #print(text)\n",
    "    text = text.lower()\n",
    "    text=text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = {}\n",
    "T['love'] = ['love','romance','romantic','love song','soulmate','relationship','relationships','marriage','crush','love triangle','sweet','young love','true love', 'need'\n",
    "            ,'young'\n",
    "            ,'girl'\n",
    "            ,'care'\n",
    "            ,'taylor swift'\n",
    "            ,'heartbeat',\n",
    "           'understanding',\n",
    "           'justin',\n",
    "           'fall out boy']\n",
    "T['sad']= ['lonely','depression','sad','loneliness','sadness','dark','broken','alone','emo','darkness','isolation','cry','homesick','melancholia','loss','melancholy','memories','regret','nostalgia','homesick','longing','radio'\n",
    "                    \n",
    " ,'forgiveness',\n",
    " 'screamo',\n",
    " 'keeper pop punk',\n",
    " 'grey',\n",
    " 'storm',\n",
    " 'light',\n",
    " 'jazz',\n",
    " 'irony',\n",
    " 'inspired by a film',\n",
    " 'sad song',\n",
    " 'post-punk', 'melancholic'\n",
    "                    ]\n",
    "#T['sad'] = ['lonely','depression','sad','loneliness','sadness','dark','broken','alone','emo','darkness','isolation','cry','homesick']\n",
    "T['breakup'] = ['breakup','break up','break-up','heartbreak','cheating','betrayal','divorce','infidelity','disillusionment','betrayal','disappointment','guilt','heartache','jealousy','leaving','unrequited love','discontentment', 'mimicking birds', 'prog', 'rain']\n",
    "#T['nostalgia'] = ['melancholia','loss','melancholy','memories','regret','nostalgia','homesick','longing','radio']\n",
    "T['death'] = ['suicidal','suicide','death','war','murder','abuse','pain','evil','funeral','drugs','addiction','alcoholism','heroin','bullying','satan','domestic abuse','cancer','cocaine','weed','dying','paranoia',\n",
    " 'hurt',\n",
    " 'devil',\n",
    " 'insanity',\n",
    " 'shoegaze',\n",
    " 'foster the people',\n",
    " 'death metal',\n",
    " 'hell',\n",
    "'mother','afterlife'\n",
    "             ]\n",
    "T['sex'] = ['sex','rape','sexy','oral sex','masturbation','sexuality','prostitution','lust','virginity','desire','voyeurism','bondage',\n",
    " 'sexual relationship',\n",
    " 'lack of romance',\n",
    " 'domination',\n",
    " 'one night stand']\n",
    "T['happy'] = ['happysongs','happy','happiness','beauty','comedy','inspiration','dream','empathy','life','christmas','holiday','hope','faith','friendship','beautiful','amazing','freedom','peace','family','friends','awesome','perseverance','funny',\n",
    "             'childhood experience'\n",
    "             ,'challenges',\n",
    "             'fashion']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M={}\n",
    "for tag in T:\n",
    "    for it in T[tag]:\n",
    "        M[it]=tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breakup': 0, 'death': 1, 'happy': 2, 'love': 4, 'sad': 3, 'sex': 5}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N ={}\n",
    "N = dict( [ (it[1],it[0]) for it in enumerate(T.keys()) ] )\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F={}\n",
    "for it in N:\n",
    "    F[N[it]]=it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2619\n"
     ]
    }
   ],
   "source": [
    "D={}\n",
    "#parte de tags\n",
    "cntSong=0\n",
    "for item in data:\n",
    "    sal=preprocess(item['lyric'])\n",
    "    if(len(sal)<120):\n",
    "        continue\n",
    "    ok=0\n",
    "    \n",
    "    #print(sal)\n",
    "    for tag in item['tags']:\n",
    "        tag=tag.lower()\n",
    "        if tag in M:\n",
    "            ok=1\n",
    "        #print(tag)\n",
    "        if not tag in D:\n",
    "            D[tag]=[]\n",
    "        D[tag].append( sal )\n",
    "    cntSong+=ok\n",
    "    #break\n",
    "print(cntSong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salida = json.dump(T, open('Tags.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3776\n"
     ]
    }
   ],
   "source": [
    "pocos=[]\n",
    "for tag in D:\n",
    "    if len(D[tag])==1:\n",
    "        pocos.append(tag)\n",
    "#for tag in pocos:\n",
    "#    D.pop(tag, None)\n",
    "    \n",
    "print(len(pocos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4494"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label=[]\n",
    "textos=[]\n",
    "\n",
    "for tag in D:\n",
    "    for s in D[tag]:\n",
    "        label.append(tag)\n",
    "        textos.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlabel=[ (N[M[i]] if (i in M) else -1) for i in label ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3163, 209, 476, 2439, 379, 531, 171]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[nlabel.count(i) for i in range(-1,6)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " vectorizer = TfidfVectorizer(ngram_range=(1,4),max_features=1000, stop_words='english',min_df=0.005  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf=vectorizer.fit(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oh oh\n",
      "say goodbye\n",
      "whoa oh\n",
      "say say\n",
      "baby baby\n",
      "don let\n",
      "know ve\n",
      "long long\n",
      "run away\n",
      "don like\n",
      "don say\n",
      "make feel\n",
      "la la la la\n",
      "cause know\n",
      "don think\n",
      "ll love\n",
      "know don\n",
      "know gonna\n",
      "ah ah\n",
      "yeah yeah\n",
      "ain got\n",
      "wanna know\n",
      "oh love\n",
      "ha ha\n",
      "baby don\n",
      "don mind\n",
      "love love love\n",
      "feels like\n",
      "set free\n",
      "time time\n",
      "want know\n",
      "love just\n",
      "want want\n",
      "just want\n",
      "just little\n",
      "ll tell\n",
      "feel like\n",
      "oh oh oh\n",
      "oh don\n",
      "time know\n",
      "ooh ooh ooh\n",
      "don don\n",
      "little bit\n",
      "love oh\n",
      "ll know\n",
      "don stop\n",
      "don try\n",
      "long time\n",
      "don need\n",
      "come home\n",
      "ll make\n",
      "know know\n",
      "just like\n",
      "oh yeah\n",
      "don know\n",
      "ve got\n",
      "don feel\n",
      "let let\n",
      "ll ll\n",
      "hey hey hey hey\n",
      "love like\n",
      "know want\n",
      "know time\n",
      "just let\n",
      "just don\n",
      "don want\n",
      "know ll\n",
      "ll come\n",
      "la la\n",
      "know just\n",
      "know don know\n",
      "don worry\n",
      "hey hey hey\n",
      "gone gone\n",
      "die die\n",
      "ve come\n",
      "hold hold\n",
      "won let\n",
      "run run\n",
      "long way\n",
      "cause don\n",
      "let know\n",
      "oh oh oh oh\n",
      "know love\n",
      "don care\n",
      "close eyes\n",
      "walk away\n",
      "know got\n",
      "oh lord\n",
      "ve seen\n",
      "say don\n",
      "oh baby\n",
      "time ll\n",
      "need love\n",
      "know know know\n",
      "right right\n",
      "far away\n",
      "don wanna\n",
      "know oh\n",
      "ooh ooh\n",
      "yeah yeah yeah\n",
      "love don\n",
      "yeah yeah yeah yeah\n",
      "ooh ooh ooh ooh\n",
      "wait wait\n",
      "la la la\n",
      "hey hey\n",
      "love love love love\n",
      "don make\n",
      "come come\n",
      "love love\n"
     ]
    }
   ],
   "source": [
    "for t in tfidf.vocabulary_:\n",
    "    if len(t.split())>1:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salida=tfidf.transform(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_total=salida.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.2, gamma=20, kernel='rbf', max_iter=5000, n_jobs=100,\n",
       "        n_neighbors=7, tol=0.001)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_prop_model = LabelSpreading(kernel='rbf', max_iter=5000, n_jobs=100)\n",
    "label_prop_model.fit(X_total, nlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_prop_model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labN= label_prop_model.label_distributions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SS={}\n",
    "for index,tag in enumerate(label):\n",
    "    if not tag in M: \n",
    "        if not tag in SS:\n",
    "            SS[tag]=[]\n",
    "            for i in labN[index]:\n",
    "                SS[tag].append(0)\n",
    "        SS[tag] = np.sum([ SS[tag],labN[index] ], axis=0)\n",
    "        #pos=0        \n",
    "        #for i in labN[index]:\n",
    "        #    SS[tag][pos] += labN[index][pos]\n",
    "        #if max(labN[index])>0.5:\n",
    "        #    act=F[np.argmax(labN[index])]\n",
    "        #else:\n",
    "        #    act=\"otro\"\n",
    "        #SS[tag].append( act )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for it in SS:\n",
    "    SS[it] = SS[it]/np.sum(SS[it])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324\n"
     ]
    }
   ],
   "source": [
    "cambios=0\n",
    "for it in SS:\n",
    "    pos = np.argmax(SS[it])\n",
    "    if SS[it][pos]<0.99 and SS[it][pos]>0.75 :\n",
    "        cambios+=1\n",
    "        T[F[pos]].append(it)\n",
    "        \n",
    "print(cambios)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
